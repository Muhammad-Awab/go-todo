
==> Audit <==
|-----------|----------------------------------------------------------------------------|----------|--------|---------|---------------------|---------------------|
|  Command  |                                    Args                                    | Profile  |  User  | Version |     Start Time      |      End Time       |
|-----------|----------------------------------------------------------------------------|----------|--------|---------|---------------------|---------------------|
| start     |                                                                            | minikube | emumba | v1.36.0 | 20 Jul 25 18:31 PKT |                     |
| start     |                                                                            | minikube | emumba | v1.36.0 | 20 Jul 25 18:33 PKT |                     |
| config    | set driver docker                                                          | minikube | emumba | v1.36.0 | 20 Jul 25 18:33 PKT | 20 Jul 25 18:33 PKT |
| start     |                                                                            | minikube | emumba | v1.36.0 | 20 Jul 25 18:34 PKT |                     |
| delete    |                                                                            | minikube | emumba | v1.36.0 | 20 Jul 25 18:34 PKT | 20 Jul 25 18:34 PKT |
| start     |                                                                            | minikube | emumba | v1.36.0 | 20 Jul 25 18:34 PKT |                     |
| start     | --driver=docker                                                            | minikube | emumba | v1.36.0 | 20 Jul 25 18:34 PKT |                     |
| start     |                                                                            | minikube | emumba | v1.36.0 | 20 Jul 25 18:34 PKT | 20 Jul 25 18:40 PKT |
| dashboard |                                                                            | minikube | emumba | v1.36.0 | 21 Jul 25 10:31 PKT |                     |
| start     |                                                                            | minikube | emumba | v1.36.0 | 21 Jul 25 10:31 PKT | 21 Jul 25 10:33 PKT |
| dashboard |                                                                            | minikube | emumba | v1.36.0 | 21 Jul 25 10:34 PKT |                     |
| start     |                                                                            | minikube | emumba | v1.36.0 | 28 Jul 25 10:54 PKT |                     |
| start     |                                                                            | minikube | emumba | v1.36.0 | 28 Jul 25 11:02 PKT |                     |
| addons    | enable storage-provisioner                                                 | minikube | emumba | v1.36.0 | 28 Jul 25 11:05 PKT |                     |
| addons    | enable default-storageclass                                                | minikube | emumba | v1.36.0 | 28 Jul 25 11:06 PKT |                     |
| stop      |                                                                            | minikube | emumba | v1.36.0 | 28 Jul 25 11:06 PKT | 28 Jul 25 11:06 PKT |
| delete    |                                                                            | minikube | emumba | v1.36.0 | 28 Jul 25 11:06 PKT | 28 Jul 25 11:06 PKT |
| start     |                                                                            | minikube | emumba | v1.36.0 | 28 Jul 25 11:06 PKT | 28 Jul 25 11:08 PKT |
| service   | cloudl-client-service                                                      | minikube | emumba | v1.36.0 | 28 Jul 25 12:10 PKT | 28 Jul 25 12:10 PKT |
| ip        |                                                                            | minikube | emumba | v1.36.0 | 28 Jul 25 12:13 PKT | 28 Jul 25 12:13 PKT |
| service   | https://github.com/Sajjadhz/MERN-stack-k8s/blob/front-end/nginx/nginx.conf | minikube | emumba | v1.36.0 | 28 Jul 25 12:29 PKT |                     |
| service   | mongodb-express-service                                                    | minikube | emumba | v1.36.0 | 28 Jul 25 12:30 PKT | 28 Jul 25 12:30 PKT |
| start     |                                                                            | minikube | emumba | v1.36.0 | 29 Jul 25 10:20 PKT | 29 Jul 25 10:21 PKT |
| ip        |                                                                            | minikube | emumba | v1.36.0 | 29 Jul 25 11:08 PKT | 29 Jul 25 11:08 PKT |
| start     |                                                                            | minikube | emumba | v1.36.0 | 05 Aug 25 11:56 PKT |                     |
| delete    |                                                                            | minikube | emumba | v1.36.0 | 05 Aug 25 12:26 PKT | 05 Aug 25 12:26 PKT |
| start     |                                                                            | minikube | emumba | v1.36.0 | 05 Aug 25 12:26 PKT |                     |
| start     |                                                                            | minikube | emumba | v1.36.0 | 05 Aug 25 12:33 PKT |                     |
|-----------|----------------------------------------------------------------------------|----------|--------|---------|---------------------|---------------------|


==> Last Start <==
Log file created at: 2025/08/05 12:33:11
Running on machine: MuhammadAwab
Binary: Built with gc go1.24.0 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0805 12:33:11.802455   54473 out.go:345] Setting OutFile to fd 1 ...
I0805 12:33:11.802874   54473 out.go:397] isatty.IsTerminal(1) = true
I0805 12:33:11.802877   54473 out.go:358] Setting ErrFile to fd 2...
I0805 12:33:11.802882   54473 out.go:397] isatty.IsTerminal(2) = true
I0805 12:33:11.803241   54473 root.go:338] Updating PATH: /home/emumba/.minikube/bin
I0805 12:33:11.805633   54473 out.go:352] Setting JSON to false
I0805 12:33:11.808432   54473 start.go:130] hostinfo: {"hostname":"MuhammadAwab","uptime":9193,"bootTime":1754369998,"procs":372,"os":"linux","platform":"ubuntu","platformFamily":"debian","platformVersion":"24.04","kernelVersion":"6.14.0-27-generic","kernelArch":"x86_64","virtualizationSystem":"kvm","virtualizationRole":"host","hostId":"42ac8bcd-3294-4d59-b91f-4f1326cfd73f"}
I0805 12:33:11.808518   54473 start.go:140] virtualization: kvm host
I0805 12:33:11.833566   54473 out.go:177] 😄  minikube v1.36.0 on Ubuntu 24.04
I0805 12:33:11.838847   54473 notify.go:220] Checking for updates...
I0805 12:33:11.839519   54473 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.33.1
I0805 12:33:11.840023   54473 driver.go:404] Setting default libvirt URI to qemu:///system
I0805 12:33:11.856310   54473 docker.go:123] docker version: linux-27.5.1:
I0805 12:33:11.856367   54473 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0805 12:33:11.871093   54473 info.go:266] docker info: {ID:8eedbb04-1dec-4b94-a284-c4446fbae3d6 Containers:5 ContainersRunning:2 ContainersPaused:0 ContainersStopped:3 Images:75 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:false BridgeNfIP6Tables:false Debug:false NFd:39 OomKillDisable:false NGoroutines:61 SystemTime:2025-08-05 12:33:11.865133538 +0500 PKT LoggingDriver:json-file CgroupDriver:systemd NEventsListener:0 KernelVersion:6.14.0-27-generic OperatingSystem:Ubuntu 24.04.2 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:8 MemTotal:16501628928 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:MuhammadAwab Labels:[] ExperimentalBuild:false ServerVersion:27.5.1 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID: Expected:} RuncCommit:{ID: Expected:} InitCommit:{ID: Expected:} SecurityOptions:[name=apparmor name=seccomp,profile=builtin name=cgroupns] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[] Warnings:<nil>}}
I0805 12:33:11.871147   54473 docker.go:318] overlay module found
I0805 12:33:11.872636   54473 out.go:177] ✨  Using the docker driver based on existing profile
I0805 12:33:11.877691   54473 start.go:304] selected driver: docker
I0805 12:33:11.877702   54473 start.go:908] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b Memory:3900 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.33.1 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.33.1 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/emumba:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0805 12:33:11.877808   54473 start.go:919] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0805 12:33:11.877871   54473 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0805 12:33:11.893608   54473 info.go:266] docker info: {ID:8eedbb04-1dec-4b94-a284-c4446fbae3d6 Containers:5 ContainersRunning:2 ContainersPaused:0 ContainersStopped:3 Images:75 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:false BridgeNfIP6Tables:false Debug:false NFd:39 OomKillDisable:false NGoroutines:61 SystemTime:2025-08-05 12:33:11.888023003 +0500 PKT LoggingDriver:json-file CgroupDriver:systemd NEventsListener:0 KernelVersion:6.14.0-27-generic OperatingSystem:Ubuntu 24.04.2 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:8 MemTotal:16501628928 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:MuhammadAwab Labels:[] ExperimentalBuild:false ServerVersion:27.5.1 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID: Expected:} RuncCommit:{ID: Expected:} InitCommit:{ID: Expected:} SecurityOptions:[name=apparmor name=seccomp,profile=builtin name=cgroupns] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[] Warnings:<nil>}}
I0805 12:33:11.894159   54473 cni.go:84] Creating CNI manager for ""
I0805 12:33:11.894200   54473 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0805 12:33:11.894237   54473 start.go:347] cluster config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b Memory:3900 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.33.1 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.33.1 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/emumba:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0805 12:33:11.895808   54473 out.go:177] 👍  Starting "minikube" primary control-plane node in "minikube" cluster
I0805 12:33:11.898470   54473 cache.go:121] Beginning downloading kic base image for docker with docker
I0805 12:33:11.899909   54473 out.go:177] 🚜  Pulling base image v0.0.47 ...
I0805 12:33:11.902651   54473 preload.go:131] Checking if preload exists for k8s version v1.33.1 and runtime docker
I0805 12:33:11.902701   54473 preload.go:146] Found local preload: /home/emumba/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.33.1-docker-overlay2-amd64.tar.lz4
I0805 12:33:11.902708   54473 cache.go:56] Caching tarball of preloaded images
I0805 12:33:11.902716   54473 image.go:81] Checking for gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b in local docker daemon
I0805 12:33:11.902821   54473 preload.go:172] Found /home/emumba/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.33.1-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0805 12:33:11.902832   54473 cache.go:59] Finished verifying existence of preloaded tar for v1.33.1 on docker
I0805 12:33:11.902933   54473 profile.go:143] Saving config to /home/emumba/.minikube/profiles/minikube/config.json ...
I0805 12:33:11.923252   54473 image.go:100] Found gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b in local docker daemon, skipping pull
I0805 12:33:11.923259   54473 cache.go:145] gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b exists in daemon, skipping load
I0805 12:33:11.923267   54473 cache.go:230] Successfully downloaded all kic artifacts
I0805 12:33:11.923282   54473 start.go:360] acquireMachinesLock for minikube: {Name:mk3c491fb3a06c7283013abeeae399acb202913f Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0805 12:33:11.923315   54473 start.go:364] duration metric: took 22.121µs to acquireMachinesLock for "minikube"
I0805 12:33:11.923324   54473 start.go:96] Skipping create...Using existing machine configuration
I0805 12:33:11.923327   54473 fix.go:54] fixHost starting: 
I0805 12:33:11.923471   54473 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0805 12:33:11.934102   54473 fix.go:112] recreateIfNeeded on minikube: state=Running err=<nil>
W0805 12:33:11.934116   54473 fix.go:138] unexpected machine state, will restart: <nil>
I0805 12:33:11.935742   54473 out.go:177] 🏃  Updating the running docker "minikube" container ...


==> Docker <==
Aug 05 07:26:32 minikube dockerd[1026]: time="2025-08-05T07:26:32.229177016Z" level=info msg="Initializing buildkit"
Aug 05 07:26:32 minikube dockerd[1026]: time="2025-08-05T07:26:32.339676036Z" level=info msg="Completed buildkit initialization"
Aug 05 07:26:32 minikube dockerd[1026]: time="2025-08-05T07:26:32.343160442Z" level=info msg="Daemon has completed initialization"
Aug 05 07:26:32 minikube dockerd[1026]: time="2025-08-05T07:26:32.343248812Z" level=info msg="API listen on [::]:2376"
Aug 05 07:26:32 minikube systemd[1]: Started Docker Application Container Engine.
Aug 05 07:26:32 minikube dockerd[1026]: time="2025-08-05T07:26:32.343340519Z" level=info msg="API listen on /var/run/docker.sock"
Aug 05 07:26:32 minikube systemd[1]: Stopping Docker Application Container Engine...
Aug 05 07:26:32 minikube dockerd[1026]: time="2025-08-05T07:26:32.350306181Z" level=info msg="Processing signal 'terminated'"
Aug 05 07:26:32 minikube dockerd[1026]: time="2025-08-05T07:26:32.352045247Z" level=info msg="stopping event stream following graceful shutdown" error="<nil>" module=libcontainerd namespace=moby
Aug 05 07:26:32 minikube dockerd[1026]: time="2025-08-05T07:26:32.352824315Z" level=info msg="Daemon shutdown complete"
Aug 05 07:26:32 minikube dockerd[1026]: time="2025-08-05T07:26:32.353058583Z" level=info msg="stopping event stream following graceful shutdown" error="context canceled" module=libcontainerd namespace=plugins.moby
Aug 05 07:26:32 minikube systemd[1]: docker.service: Deactivated successfully.
Aug 05 07:26:32 minikube systemd[1]: Stopped Docker Application Container Engine.
Aug 05 07:26:32 minikube systemd[1]: Starting Docker Application Container Engine...
Aug 05 07:26:32 minikube dockerd[1326]: time="2025-08-05T07:26:32.387100276Z" level=info msg="Starting up"
Aug 05 07:26:32 minikube dockerd[1326]: time="2025-08-05T07:26:32.387926388Z" level=info msg="OTEL tracing is not configured, using no-op tracer provider"
Aug 05 07:26:32 minikube dockerd[1326]: time="2025-08-05T07:26:32.394388714Z" level=info msg="Creating a containerd client" address=/run/containerd/containerd.sock timeout=1m0s
Aug 05 07:26:32 minikube dockerd[1326]: time="2025-08-05T07:26:32.401917966Z" level=info msg="[graphdriver] trying configured driver: overlay2"
Aug 05 07:26:32 minikube dockerd[1326]: time="2025-08-05T07:26:32.412567624Z" level=info msg="Loading containers: start."
Aug 05 07:26:33 minikube dockerd[1326]: time="2025-08-05T07:26:33.007956787Z" level=warning msg="Error (Unable to complete atomic operation, key modified) deleting object [endpoint_count fd30f1b71429b410706c2f4dcbd0d85af899e30251e0a937a69451f681b232dc], retrying...."
Aug 05 07:26:33 minikube dockerd[1326]: time="2025-08-05T07:26:33.036638077Z" level=info msg="Loading containers: done."
Aug 05 07:26:33 minikube dockerd[1326]: time="2025-08-05T07:26:33.044619197Z" level=info msg="Docker daemon" commit=01f442b containerd-snapshotter=false storage-driver=overlay2 version=28.1.1
Aug 05 07:26:33 minikube dockerd[1326]: time="2025-08-05T07:26:33.044650000Z" level=info msg="Initializing buildkit"
Aug 05 07:26:33 minikube dockerd[1326]: time="2025-08-05T07:26:33.133342207Z" level=info msg="Completed buildkit initialization"
Aug 05 07:26:33 minikube dockerd[1326]: time="2025-08-05T07:26:33.137200236Z" level=info msg="Daemon has completed initialization"
Aug 05 07:26:33 minikube dockerd[1326]: time="2025-08-05T07:26:33.137249475Z" level=info msg="API listen on /var/run/docker.sock"
Aug 05 07:26:33 minikube dockerd[1326]: time="2025-08-05T07:26:33.137287317Z" level=info msg="API listen on [::]:2376"
Aug 05 07:26:33 minikube systemd[1]: Started Docker Application Container Engine.
Aug 05 07:26:33 minikube systemd[1]: Starting CRI Interface for Docker Application Container Engine...
Aug 05 07:26:33 minikube cri-dockerd[1627]: time="2025-08-05T07:26:33Z" level=info msg="Starting cri-dockerd dev (HEAD)"
Aug 05 07:26:33 minikube cri-dockerd[1627]: time="2025-08-05T07:26:33Z" level=info msg="Connecting to docker on the Endpoint unix:///var/run/docker.sock"
Aug 05 07:26:33 minikube cri-dockerd[1627]: time="2025-08-05T07:26:33Z" level=info msg="Start docker client with request timeout 0s"
Aug 05 07:26:33 minikube cri-dockerd[1627]: time="2025-08-05T07:26:33Z" level=info msg="Hairpin mode is set to hairpin-veth"
Aug 05 07:26:33 minikube cri-dockerd[1627]: time="2025-08-05T07:26:33Z" level=info msg="Loaded network plugin cni"
Aug 05 07:26:33 minikube cri-dockerd[1627]: time="2025-08-05T07:26:33Z" level=info msg="Docker cri networking managed by network plugin cni"
Aug 05 07:26:33 minikube cri-dockerd[1627]: time="2025-08-05T07:26:33Z" level=info msg="Setting cgroupDriver systemd"
Aug 05 07:26:33 minikube cri-dockerd[1627]: time="2025-08-05T07:26:33Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:,},}"
Aug 05 07:26:33 minikube cri-dockerd[1627]: time="2025-08-05T07:26:33Z" level=info msg="Starting the GRPC backend for the Docker CRI interface."
Aug 05 07:26:33 minikube cri-dockerd[1627]: time="2025-08-05T07:26:33Z" level=info msg="Start cri-dockerd grpc backend"
Aug 05 07:26:33 minikube systemd[1]: Started CRI Interface for Docker Application Container Engine.
Aug 05 07:26:42 minikube cri-dockerd[1627]: time="2025-08-05T07:26:42Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/2ca9e338f7f0788aeb7f3da3d14a3389db5dd7c09c10ead5f203414346d77996/resolv.conf as [nameserver 192.168.49.1 options edns0 trust-ad ndots:0]"
Aug 05 07:26:42 minikube cri-dockerd[1627]: time="2025-08-05T07:26:42Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/69a248931adc31354e2161732a0d3fe8736c124d1a7a9f3655fea29892d27285/resolv.conf as [nameserver 192.168.49.1 options edns0 trust-ad ndots:0]"
Aug 05 07:26:42 minikube cri-dockerd[1627]: time="2025-08-05T07:26:42Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/931636198e53d126cbc7888efcb41f26271cff6b11db826c2e5872546d0109ae/resolv.conf as [nameserver 192.168.49.1 options trust-ad ndots:0 edns0]"
Aug 05 07:26:42 minikube cri-dockerd[1627]: time="2025-08-05T07:26:42Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/3620371a28c80b0a33e5612e22cc811214a12d61f7b228eb321d986255abad65/resolv.conf as [nameserver 192.168.49.1 options edns0 trust-ad ndots:0]"
Aug 05 07:27:13 minikube dockerd[1326]: time="2025-08-05T07:27:13.242618675Z" level=info msg="ignoring event" container=437a1b5f4ccc97f241584813b5139c5c1f3eb9e1f7334f5175d8c80e8810c6a6 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 05 07:27:24 minikube dockerd[1326]: time="2025-08-05T07:27:24.288103714Z" level=info msg="ignoring event" container=8f6b4a251524774db8c129df8dd99b2417ff44712af1b5e7c5a2e68257ee8f3b module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 05 07:27:59 minikube dockerd[1326]: time="2025-08-05T07:27:59.676413014Z" level=info msg="ignoring event" container=0810080e91545b7ec075a5c3f53f2488b532a9b07117c8fa481ea485b5fa8d72 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 05 07:28:10 minikube dockerd[1326]: time="2025-08-05T07:28:10.951724669Z" level=info msg="ignoring event" container=2cbc9fb6daf7a3b526f2390a6de942f32316f9c15c62225bd53ddc058ddd3e39 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 05 07:28:48 minikube dockerd[1326]: time="2025-08-05T07:28:48.330233045Z" level=info msg="ignoring event" container=a8b7252a30019b64ad7b8e71ab4f1e2183f656a282af9cbdb9c339763e168707 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 05 07:28:57 minikube dockerd[1326]: time="2025-08-05T07:28:57.174961678Z" level=info msg="ignoring event" container=51172632b1495dce9f1a1f6980611c4c6089b6a02a70cbe0117ce50389756e33 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 05 07:29:45 minikube dockerd[1326]: time="2025-08-05T07:29:45.757558267Z" level=info msg="ignoring event" container=453838ea4ac61fd723957afa68425ff89e2ea7c2c805713098dccb4880260dbf module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 05 07:29:56 minikube dockerd[1326]: time="2025-08-05T07:29:56.394342356Z" level=info msg="ignoring event" container=8a22eb894ae102d2d8072f99c293fec4e075a8ceaf26c275818d80c05136e050 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 05 07:30:46 minikube cri-dockerd[1627]: W0805 07:30:46.060415    1627 logging.go:59] [core] [Server #1] grpc: Server.processUnaryRPC failed to write status: connection error: desc = "transport is closing"
Aug 05 07:30:46 minikube cri-dockerd[1627]: W0805 07:30:46.061999    1627 logging.go:59] [core] [Server #1] grpc: Server.processUnaryRPC failed to write status: connection error: desc = "transport is closing"
Aug 05 07:30:47 minikube dockerd[1326]: time="2025-08-05T07:30:47.385963241Z" level=info msg="ignoring event" container=931636198e53d126cbc7888efcb41f26271cff6b11db826c2e5872546d0109ae module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 05 07:30:58 minikube dockerd[1326]: time="2025-08-05T07:30:58.020090301Z" level=info msg="ignoring event" container=3620371a28c80b0a33e5612e22cc811214a12d61f7b228eb321d986255abad65 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 05 07:31:10 minikube dockerd[1326]: time="2025-08-05T07:31:10.606784254Z" level=info msg="ignoring event" container=9fd78bc084077e4dbd36d22da823a1a0922cff049d96499a8e10b0c0c58f35a4 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 05 07:31:10 minikube dockerd[1326]: time="2025-08-05T07:31:10.607523580Z" level=info msg="ignoring event" container=69a248931adc31354e2161732a0d3fe8736c124d1a7a9f3655fea29892d27285 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 05 07:31:15 minikube dockerd[1326]: time="2025-08-05T07:31:15.816438650Z" level=info msg="ignoring event" container=2ca9e338f7f0788aeb7f3da3d14a3389db5dd7c09c10ead5f203414346d77996 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 05 07:31:18 minikube dockerd[1326]: time="2025-08-05T07:31:18.413690419Z" level=info msg="ignoring event" container=513057171c08a5969312b8e831e135cb7fd5bec9754f5c3ddc4150c9bfdc4c1e module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"


==> container status <==
CONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID              POD
9fd78bc084077       c6ab243b29f82       2 minutes ago       Exited              kube-apiserver            4                   69a248931adc3       kube-apiserver-minikube
8a22eb894ae10       ef43894fa110c       4 minutes ago       Exited              kube-controller-manager   3                   3620371a28c80       kube-controller-manager-minikube
453838ea4ac61       c6ab243b29f82       4 minutes ago       Exited              kube-apiserver            3                   69a248931adc3       kube-apiserver-minikube
f4e65c442b15f       398c985c0d950       6 minutes ago       Running             kube-scheduler            0                   931636198e53d       kube-scheduler-minikube


==> describe nodes <==
command /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" failed with error: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0805 07:33:20.239277    4067 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0805 07:33:20.240755    4067 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0805 07:33:20.242135    4067 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0805 07:33:20.243632    4067 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0805 07:33:20.245018    4067 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?


==> dmesg <==
[  +0.017163] i8042: Warning: Keylock active
[  +0.007076] device-mapper: core: CONFIG_IMA_DISABLE_HTABLE is disabled. Duplicate IMA measurements will not be recorded in the IMA log.
[  +0.017481] ENERGY_PERF_BIAS: Set to 'normal', was 'performance'
[  +0.170856] wmi_bus wmi_bus-PNP0C14:02: [Firmware Bug]: WQBC data block query control method not found
[  +0.050767] usb usb3-port4: over-current condition
[  +0.334025] ACPI Error: Thread 2378608768 cannot release Mutex [ECMX] acquired by thread 2166030336 (20240827/exmutex-378)

[  +0.000008] No Local Variables are initialized for Method [_Q66]

[  +0.000002] No Arguments are initialized for method [_Q66]

[  +0.000002] ACPI Error: Aborting method \_SB.PC00.LPCB.ECDV._Q66 due to previous error (AE_AML_NOT_OWNER) (20240827/psparse-529)
[  +0.002478] ACPI Error: Thread 2167865344 cannot release Mutex [ECMX] acquired by thread 2166030336 (20240827/exmutex-378)

[  +0.000004] No Local Variables are initialized for Method [_Q66]

[  +0.000002] No Arguments are initialized for method [_Q66]

[  +0.000001] ACPI Error: Aborting method \_SB.PC00.LPCB.ECDV._Q66 due to previous error (AE_AML_NOT_OWNER) (20240827/psparse-529)
[  +0.042933] ACPI Error: Thread 2378629120 cannot release Mutex [ECMX] acquired by thread 2166030336 (20240827/exmutex-378)

[  +0.000007] No Local Variables are initialized for Method [_Q66]

[  +0.000001] No Arguments are initialized for method [_Q66]

[  +0.000002] ACPI Error: Aborting method \_SB.PC00.LPCB.ECDV._Q66 due to previous error (AE_AML_NOT_OWNER) (20240827/psparse-529)
[  +0.019186] ACPI Error: Cannot release Mutex [ECMX], not acquired (20240827/exmutex-357)

[  +0.000004] No Local Variables are initialized for Method [_Q66]

[  +0.000002] No Arguments are initialized for method [_Q66]

[  +0.000001] ACPI Error: Aborting method \_SB.PC00.LPCB.ECDV._Q66 due to previous error (AE_AML_MUTEX_NOT_ACQUIRED) (20240827/psparse-529)
[  +0.668851] systemd[1]: Configuration file /etc/systemd/system/SolarwindsDiscoveryAgent.service is marked executable. Please remove executable permission bits. Proceeding anyway.
[  +0.000005] systemd[1]: Configuration file /etc/systemd/system/SolarwindsDiscoveryAgent.service is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.
[Aug 5 05:00] spi-nor spi0.0: supply vcc not found, using dummy regulator
[  +0.489038] iwlwifi 0000:00:14.3: timeout waiting for FW reset ACK (inta_hw=0x4)
[  +0.423515] skl_hda_dsp_generic skl_hda_dsp_generic: ASoC: Parent card not yet available, widget card binding deferred
[  +0.110065] nvme nvme0: using unchecked data buffer
[  +0.172170] skl_hda_dsp_generic skl_hda_dsp_generic: hda_dsp_hdmi_build_controls: no PCM in topology for HDMI converter 3
[  +0.133847] ACPI BIOS Error (bug): Could not resolve symbol [\_TZ.ETMD], AE_NOT_FOUND (20240827/psargs-332)

[  +0.000015] No Local Variables are initialized for Method [_OSC]

[  +0.000002] Initialized Arguments for Method [_OSC]:  (4 arguments defined for method invocation)
[  +0.000001]   Arg0:   00000000cac20b58 <Obj>           Buffer(16) 5D A8 3B B2 B7 C8 42 35
[  +0.000012]   Arg1:   000000003e4a84e8 <Obj>           Integer 0000000000000001
[  +0.000004]   Arg2:   0000000013e2b966 <Obj>           Integer 0000000000000002
[  +0.000005]   Arg3:   0000000038aabb1a <Obj>           Buffer(8) 00 00 00 00 05 00 00 00

[  +0.000010] ACPI Error: Aborting method \_SB.IETM._OSC due to previous error (AE_NOT_FOUND) (20240827/psparse-529)
[  +0.276755] Bluetooth: hci0: HCI LE Coded PHY feature bit is set, but its usage is not supported.
[  +0.343482] kauditd_printk_skb: 145 callbacks suppressed
[  +0.455156] eset_rtp: loading out-of-tree module taints kernel.
[ +12.727415] warning: `ThreadPoolForeg' uses wireless extensions which will stop working for Wi-Fi 7 hardware; use nl80211
[Aug 5 05:41] workqueue: delayed_fput hogged CPU for >10000us 4 times, consider switching to WQ_UNBOUND
[  +4.997822] workqueue: delayed_fput hogged CPU for >10000us 5 times, consider switching to WQ_UNBOUND
[Aug 5 05:43] workqueue: delayed_fput hogged CPU for >10000us 7 times, consider switching to WQ_UNBOUND
[Aug 5 05:46] workqueue: delayed_fput hogged CPU for >10000us 11 times, consider switching to WQ_UNBOUND
[Aug 5 05:54] workqueue: delayed_fput hogged CPU for >10000us 19 times, consider switching to WQ_UNBOUND


==> kernel <==
 07:33:20 up  2:33,  0 users,  load average: 4.32, 7.88, 8.57
Linux minikube 6.14.0-27-generic #27~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jul 22 17:38:49 UTC 2 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.5 LTS"


==> kube-apiserver [453838ea4ac6] <==
I0805 07:29:20.779912       1 options.go:249] external host was not specified, using 192.168.49.2
I0805 07:29:20.788654       1 server.go:147] Version: v1.33.1
I0805 07:29:20.789208       1 server.go:149] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
W0805 07:29:21.614325       1 logging.go:55] [core] [Channel #1 SubChannel #3]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:29:21.614522       1 logging.go:55] [core] [Channel #2 SubChannel #4]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
I0805 07:29:21.647986       1 shared_informer.go:350] "Waiting for caches to sync" controller="node_authorizer"
I0805 07:29:21.660256       1 shared_informer.go:350] "Waiting for caches to sync" controller="*generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]"
I0805 07:29:21.669638       1 plugins.go:157] Loaded 14 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,PodTopologyLabels,MutatingAdmissionPolicy,MutatingAdmissionWebhook.
I0805 07:29:21.669664       1 plugins.go:160] Loaded 13 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,ClusterTrustBundleAttest,CertificateSubjectRestriction,ValidatingAdmissionPolicy,ValidatingAdmissionWebhook,ResourceQuota.
I0805 07:29:21.706065       1 instance.go:233] Using reconciler: lease
W0805 07:29:21.716471       1 logging.go:55] [core] [Channel #5 SubChannel #6]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:29:22.615425       1 logging.go:55] [core] [Channel #2 SubChannel #4]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:29:22.615869       1 logging.go:55] [core] [Channel #1 SubChannel #3]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:29:22.717811       1 logging.go:55] [core] [Channel #5 SubChannel #6]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:29:24.024809       1 logging.go:55] [core] [Channel #2 SubChannel #4]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:29:24.055504       1 logging.go:55] [core] [Channel #5 SubChannel #6]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:29:24.391916       1 logging.go:55] [core] [Channel #1 SubChannel #3]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:29:26.689386       1 logging.go:55] [core] [Channel #2 SubChannel #4]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:29:26.850512       1 logging.go:55] [core] [Channel #5 SubChannel #6]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:29:27.177454       1 logging.go:55] [core] [Channel #1 SubChannel #3]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:29:31.071089       1 logging.go:55] [core] [Channel #2 SubChannel #4]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:29:31.106806       1 logging.go:55] [core] [Channel #5 SubChannel #6]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:29:31.286421       1 logging.go:55] [core] [Channel #1 SubChannel #3]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:29:36.984097       1 logging.go:55] [core] [Channel #2 SubChannel #4]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:29:38.957113       1 logging.go:55] [core] [Channel #5 SubChannel #6]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:29:39.079755       1 logging.go:55] [core] [Channel #1 SubChannel #3]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
F0805 07:29:41.710351       1 instance.go:226] Error creating leases: error creating storage factory: context deadline exceeded


==> kube-apiserver [9fd78bc08407] <==
I0805 07:30:45.182803       1 options.go:249] external host was not specified, using 192.168.49.2
I0805 07:30:45.185575       1 server.go:147] Version: v1.33.1
I0805 07:30:45.185605       1 server.go:149] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
W0805 07:30:46.331207       1 logging.go:55] [core] [Channel #1 SubChannel #2]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:30:46.333734       1 logging.go:55] [core] [Channel #3 SubChannel #4]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
I0805 07:30:46.421811       1 shared_informer.go:350] "Waiting for caches to sync" controller="node_authorizer"
I0805 07:30:46.430097       1 shared_informer.go:350] "Waiting for caches to sync" controller="*generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]"
I0805 07:30:46.439733       1 plugins.go:157] Loaded 14 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,PodTopologyLabels,MutatingAdmissionPolicy,MutatingAdmissionWebhook.
I0805 07:30:46.439795       1 plugins.go:160] Loaded 13 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,ClusterTrustBundleAttest,CertificateSubjectRestriction,ValidatingAdmissionPolicy,ValidatingAdmissionWebhook,ResourceQuota.
I0805 07:30:46.478230       1 instance.go:233] Using reconciler: lease
W0805 07:30:46.479514       1 logging.go:55] [core] [Channel #5 SubChannel #6]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:30:47.332472       1 logging.go:55] [core] [Channel #1 SubChannel #2]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:30:47.334885       1 logging.go:55] [core] [Channel #3 SubChannel #4]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:30:47.480807       1 logging.go:55] [core] [Channel #5 SubChannel #6]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:30:49.010662       1 logging.go:55] [core] [Channel #3 SubChannel #4]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:30:49.113468       1 logging.go:55] [core] [Channel #1 SubChannel #2]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:30:49.336314       1 logging.go:55] [core] [Channel #5 SubChannel #6]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:30:51.214432       1 logging.go:55] [core] [Channel #1 SubChannel #2]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:30:51.652939       1 logging.go:55] [core] [Channel #3 SubChannel #4]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:30:51.913496       1 logging.go:55] [core] [Channel #5 SubChannel #6]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:30:55.140018       1 logging.go:55] [core] [Channel #1 SubChannel #2]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:30:55.415917       1 logging.go:55] [core] [Channel #5 SubChannel #6]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:30:56.199867       1 logging.go:55] [core] [Channel #3 SubChannel #4]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:31:01.703064       1 logging.go:55] [core] [Channel #3 SubChannel #4]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:31:01.857350       1 logging.go:55] [core] [Channel #5 SubChannel #6]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0805 07:31:02.283466       1 logging.go:55] [core] [Channel #1 SubChannel #2]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
F0805 07:31:06.480777       1 instance.go:226] Error creating leases: error creating storage factory: context deadline exceeded


==> kube-controller-manager [8a22eb894ae1] <==
I0805 07:29:32.422348       1 serving.go:386] Generated self-signed cert in-memory
I0805 07:29:33.774565       1 controllermanager.go:188] "Starting" version="v1.33.1"
I0805 07:29:33.774594       1 controllermanager.go:190] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0805 07:29:33.777701       1 dynamic_cafile_content.go:161] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0805 07:29:33.777800       1 dynamic_cafile_content.go:161] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0805 07:29:33.778981       1 secure_serving.go:211] Serving securely on 127.0.0.1:10257
I0805 07:29:33.779046       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
E0805 07:29:52.724149       1 controllermanager.go:242] "Error building controller context" err="failed to wait for apiserver being healthy: timed out waiting for the condition: failed to get apiserver /healthz status: Get \"https://192.168.49.2:8443/healthz\": dial tcp 192.168.49.2:8443: connect: connection refused"


==> kube-scheduler [f4e65c442b15] <==
E0805 07:30:25.140727       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ReplicaSet: Get \"https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicaSet"
E0805 07:30:27.572915       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSIDriver: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSIDriver"
E0805 07:30:28.120103       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ReplicationController: Get \"https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicationController"
E0805 07:30:30.860614       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Pod: Get \"https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%21%3DSucceeded%2Cstatus.phase%21%3DFailed&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Pod"
E0805 07:30:37.337310       1 reflector.go:200] "Failed to watch" err="failed to list *v1.StatefulSet: Get \"https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StatefulSet"
E0805 07:30:44.184113       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PersistentVolume: Get \"https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolume"
E0805 07:30:56.465774       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Service: Get \"https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0\": net/http: TLS handshake timeout" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Service"
E0805 07:30:58.465914       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PodDisruptionBudget: Get \"https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0\": net/http: TLS handshake timeout" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PodDisruptionBudget"
E0805 07:31:00.494867       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ConfigMap: Get \"https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&limit=500&resourceVersion=0\": net/http: TLS handshake timeout" logger="UnhandledError" reflector="runtime/asm_amd64.s:1700" type="*v1.ConfigMap"
E0805 07:31:02.580041       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSIStorageCapacity: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0\": net/http: TLS handshake timeout" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSIStorageCapacity"
E0805 07:31:02.783260       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PersistentVolumeClaim: Get \"https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0\": net/http: TLS handshake timeout" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolumeClaim"
E0805 07:31:07.488785       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Node: Get \"https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:38902->192.168.49.2:8443: read: connection reset by peer" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Node"
E0805 07:31:07.489046       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Namespace: Get \"https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:49144->192.168.49.2:8443: read: connection reset by peer" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Namespace"
E0805 07:31:07.489434       1 reflector.go:200] "Failed to watch" err="failed to list *v1.VolumeAttachment: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/volumeattachments?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:38894->192.168.49.2:8443: read: connection reset by peer" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.VolumeAttachment"
E0805 07:31:15.483882       1 reflector.go:200] "Failed to watch" err="failed to list *v1.StorageClass: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StorageClass"
E0805 07:31:16.599837       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ReplicaSet: Get \"https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicaSet"
E0805 07:31:16.820423       1 reflector.go:200] "Failed to watch" err="failed to list *v1.StatefulSet: Get \"https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StatefulSet"
E0805 07:31:21.093512       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSINode: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSINode"
E0805 07:31:21.473957       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Pod: Get \"https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%21%3DSucceeded%2Cstatus.phase%21%3DFailed&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Pod"
E0805 07:31:24.160501       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ReplicationController: Get \"https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicationController"
E0805 07:31:27.532224       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSIDriver: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSIDriver"
E0805 07:31:35.684555       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Service: Get \"https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Service"
E0805 07:31:39.224781       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Namespace: Get \"https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Namespace"
E0805 07:31:41.289416       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PersistentVolume: Get \"https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolume"
E0805 07:31:41.839590       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PersistentVolumeClaim: Get \"https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolumeClaim"
E0805 07:31:48.716689       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PodDisruptionBudget: Get \"https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PodDisruptionBudget"
E0805 07:31:52.311173       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSINode: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSINode"
E0805 07:31:52.439133       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSIStorageCapacity: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSIStorageCapacity"
E0805 07:31:54.710955       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Pod: Get \"https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%21%3DSucceeded%2Cstatus.phase%21%3DFailed&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Pod"
E0805 07:31:55.470285       1 reflector.go:200] "Failed to watch" err="failed to list *v1.StatefulSet: Get \"https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StatefulSet"
E0805 07:31:55.506062       1 reflector.go:200] "Failed to watch" err="failed to list *v1.VolumeAttachment: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/volumeattachments?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.VolumeAttachment"
E0805 07:31:58.591988       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ConfigMap: Get \"https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="runtime/asm_amd64.s:1700" type="*v1.ConfigMap"
E0805 07:31:59.732178       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ReplicationController: Get \"https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicationController"
E0805 07:32:01.804962       1 reflector.go:200] "Failed to watch" err="failed to list *v1.StorageClass: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StorageClass"
E0805 07:32:02.828592       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Node: Get \"https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Node"
E0805 07:32:04.777154       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSIDriver: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSIDriver"
E0805 07:32:11.053265       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ReplicaSet: Get \"https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicaSet"
E0805 07:32:16.537744       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Service: Get \"https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Service"
E0805 07:32:21.073467       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PersistentVolume: Get \"https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolume"
E0805 07:32:24.677117       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PodDisruptionBudget: Get \"https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PodDisruptionBudget"
E0805 07:32:27.940255       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PersistentVolumeClaim: Get \"https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolumeClaim"
E0805 07:32:31.812757       1 reflector.go:200] "Failed to watch" err="failed to list *v1.VolumeAttachment: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/volumeattachments?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.VolumeAttachment"
E0805 07:32:32.215093       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ReplicationController: Get \"https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicationController"
E0805 07:32:33.053874       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ConfigMap: Get \"https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="runtime/asm_amd64.s:1700" type="*v1.ConfigMap"
E0805 07:32:33.212157       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Namespace: Get \"https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Namespace"
E0805 07:32:34.568261       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Node: Get \"https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Node"
E0805 07:32:39.287156       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSINode: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSINode"
E0805 07:32:42.260279       1 reflector.go:200] "Failed to watch" err="failed to list *v1.StatefulSet: Get \"https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StatefulSet"
E0805 07:32:45.068850       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSIDriver: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSIDriver"
E0805 07:32:47.057009       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Pod: Get \"https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%21%3DSucceeded%2Cstatus.phase%21%3DFailed&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Pod"
E0805 07:32:47.263717       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSIStorageCapacity: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSIStorageCapacity"
E0805 07:32:47.864685       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ReplicaSet: Get \"https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicaSet"
E0805 07:32:51.803278       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Service: Get \"https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Service"
E0805 07:32:53.327347       1 reflector.go:200] "Failed to watch" err="failed to list *v1.StorageClass: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StorageClass"
E0805 07:33:03.472114       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ConfigMap: Get \"https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="runtime/asm_amd64.s:1700" type="*v1.ConfigMap"
E0805 07:33:09.656403       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PodDisruptionBudget: Get \"https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PodDisruptionBudget"
E0805 07:33:10.891551       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSINode: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSINode"
E0805 07:33:15.027095       1 reflector.go:200] "Failed to watch" err="failed to list *v1.VolumeAttachment: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/volumeattachments?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.VolumeAttachment"
E0805 07:33:15.464973       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Node: Get \"https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Node"
E0805 07:33:16.289014       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PersistentVolume: Get \"https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolume"


==> kubelet <==
Aug 05 07:30:02 minikube kubelet[2079]: E0805 07:30:02.711600    2079 kubelet.go:3305] "No need to create a mirror pod, since failed to get node info from the cluster" err="node \"minikube\" not found" node="minikube"
Aug 05 07:30:03 minikube kubelet[2079]: E0805 07:30:03.233381    2079 certificate_manager.go:596] "Failed while requesting a signed certificate from the control plane" err="cannot create certificate signing request: Post \"https://192.168.49.2:8443/apis/certificates.k8s.io/v1/certificatesigningrequests\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="kubernetes.io/kube-apiserver-client-kubelet.UnhandledError"
Aug 05 07:30:03 minikube kubelet[2079]: E0805 07:30:03.329911    2079 kubelet.go:3305] "No need to create a mirror pod, since failed to get node info from the cluster" err="node \"minikube\" not found" node="minikube"
Aug 05 07:30:03 minikube kubelet[2079]: I0805 07:30:03.329998    2079 scope.go:117] "RemoveContainer" containerID="8a22eb894ae102d2d8072f99c293fec4e075a8ceaf26c275818d80c05136e050"
Aug 05 07:30:03 minikube kubelet[2079]: E0805 07:30:03.330174    2079 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(0378f173c980f85a71d36305bacb0ad1)\"" pod="kube-system/kube-controller-manager-minikube" podUID="0378f173c980f85a71d36305bacb0ad1"
Aug 05 07:30:03 minikube kubelet[2079]: I0805 07:30:03.797007    2079 kubelet_node_status.go:75] "Attempting to register node" node="minikube"
Aug 05 07:30:03 minikube kubelet[2079]: E0805 07:30:03.797509    2079 kubelet_node_status.go:107] "Unable to register node with API server" err="Post \"https://192.168.49.2:8443/api/v1/nodes\": dial tcp 192.168.49.2:8443: connect: connection refused" node="minikube"
Aug 05 07:30:03 minikube kubelet[2079]: E0805 07:30:03.797585    2079 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://192.168.49.2:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused" interval="7s"
Aug 05 07:30:04 minikube kubelet[2079]: I0805 07:30:04.439795    2079 scope.go:117] "RemoveContainer" containerID="51172632b1495dce9f1a1f6980611c4c6089b6a02a70cbe0117ce50389756e33"
Aug 05 07:30:05 minikube kubelet[2079]: I0805 07:30:05.361327    2079 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="a8b7252a30019b64ad7b8e71ab4f1e2183f656a282af9cbdb9c339763e168707"
Aug 05 07:30:05 minikube kubelet[2079]: E0805 07:30:05.362366    2079 kubelet.go:3305] "No need to create a mirror pod, since failed to get node info from the cluster" err="node \"minikube\" not found" node="minikube"
Aug 05 07:30:05 minikube kubelet[2079]: I0805 07:30:05.362437    2079 scope.go:117] "RemoveContainer" containerID="453838ea4ac61fd723957afa68425ff89e2ea7c2c805713098dccb4880260dbf"
Aug 05 07:30:05 minikube kubelet[2079]: E0805 07:30:05.362610    2079 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-apiserver\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-apiserver pod=kube-apiserver-minikube_kube-system(78e1292e1d47cc7d09b2c6f5826fa624)\"" pod="kube-system/kube-apiserver-minikube" podUID="78e1292e1d47cc7d09b2c6f5826fa624"
Aug 05 07:30:05 minikube kubelet[2079]: E0805 07:30:05.789094    2079 kubelet.go:3305] "No need to create a mirror pod, since failed to get node info from the cluster" err="node \"minikube\" not found" node="minikube"
Aug 05 07:30:05 minikube kubelet[2079]: I0805 07:30:05.790390    2079 scope.go:117] "RemoveContainer" containerID="8a22eb894ae102d2d8072f99c293fec4e075a8ceaf26c275818d80c05136e050"
Aug 05 07:30:05 minikube kubelet[2079]: E0805 07:30:05.790647    2079 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(0378f173c980f85a71d36305bacb0ad1)\"" pod="kube-system/kube-controller-manager-minikube" podUID="0378f173c980f85a71d36305bacb0ad1"
Aug 05 07:30:09 minikube kubelet[2079]: E0805 07:30:09.849839    2079 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://192.168.49.2:8443/api/v1/namespaces/default/events\": dial tcp 192.168.49.2:8443: connect: connection refused" event="&Event{ObjectMeta:{minikube.1858ce399cd6d19b  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Node,Namespace:,Name:minikube,UID:minikube,APIVersion:,ResourceVersion:,FieldPath:,},Reason:NodeHasSufficientMemory,Message:Node minikube status is now: NodeHasSufficientMemory,Source:EventSource{Component:kubelet,Host:minikube,},FirstTimestamp:2025-08-05 07:26:41.700589979 +0000 UTC m=+0.291769774,LastTimestamp:2025-08-05 07:26:41.700589979 +0000 UTC m=+0.291769774,Count:1,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:minikube,}"
Aug 05 07:30:10 minikube kubelet[2079]: E0805 07:30:10.799276    2079 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://192.168.49.2:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused" interval="7s"
Aug 05 07:30:10 minikube kubelet[2079]: I0805 07:30:10.803382    2079 kubelet_node_status.go:75] "Attempting to register node" node="minikube"
Aug 05 07:30:10 minikube kubelet[2079]: E0805 07:30:10.805271    2079 kubelet_node_status.go:107] "Unable to register node with API server" err="Post \"https://192.168.49.2:8443/api/v1/nodes\": dial tcp 192.168.49.2:8443: connect: connection refused" node="minikube"
Aug 05 07:30:11 minikube kubelet[2079]: E0805 07:30:11.772454    2079 eviction_manager.go:292] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"minikube\" not found"
Aug 05 07:30:16 minikube kubelet[2079]: E0805 07:30:16.712071    2079 kubelet.go:3305] "No need to create a mirror pod, since failed to get node info from the cluster" err="node \"minikube\" not found" node="minikube"
Aug 05 07:30:16 minikube kubelet[2079]: I0805 07:30:16.712173    2079 scope.go:117] "RemoveContainer" containerID="453838ea4ac61fd723957afa68425ff89e2ea7c2c805713098dccb4880260dbf"
Aug 05 07:30:16 minikube kubelet[2079]: E0805 07:30:16.712400    2079 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-apiserver\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-apiserver pod=kube-apiserver-minikube_kube-system(78e1292e1d47cc7d09b2c6f5826fa624)\"" pod="kube-system/kube-apiserver-minikube" podUID="78e1292e1d47cc7d09b2c6f5826fa624"
Aug 05 07:30:17 minikube kubelet[2079]: I0805 07:30:17.489384    2079 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="51172632b1495dce9f1a1f6980611c4c6089b6a02a70cbe0117ce50389756e33"
Aug 05 07:30:17 minikube kubelet[2079]: E0805 07:30:17.491640    2079 kubelet.go:3305] "No need to create a mirror pod, since failed to get node info from the cluster" err="node \"minikube\" not found" node="minikube"
Aug 05 07:30:17 minikube kubelet[2079]: I0805 07:30:17.491881    2079 scope.go:117] "RemoveContainer" containerID="8a22eb894ae102d2d8072f99c293fec4e075a8ceaf26c275818d80c05136e050"
Aug 05 07:30:17 minikube kubelet[2079]: E0805 07:30:17.492650    2079 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(0378f173c980f85a71d36305bacb0ad1)\"" pod="kube-system/kube-controller-manager-minikube" podUID="0378f173c980f85a71d36305bacb0ad1"
Aug 05 07:30:17 minikube kubelet[2079]: E0805 07:30:17.799839    2079 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://192.168.49.2:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused" interval="7s"
Aug 05 07:30:17 minikube kubelet[2079]: I0805 07:30:17.807050    2079 kubelet_node_status.go:75] "Attempting to register node" node="minikube"
Aug 05 07:30:17 minikube kubelet[2079]: E0805 07:30:17.807505    2079 kubelet_node_status.go:107] "Unable to register node with API server" err="Post \"https://192.168.49.2:8443/api/v1/nodes\": dial tcp 192.168.49.2:8443: connect: connection refused" node="minikube"
Aug 05 07:30:17 minikube kubelet[2079]: E0805 07:30:17.850260    2079 reflector.go:200] "Failed to watch" err="failed to list *v1.Service: Get \"https://192.168.49.2:8443/api/v1/services?fieldSelector=spec.clusterIP%21%3DNone&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Service"
Aug 05 07:30:19 minikube kubelet[2079]: E0805 07:30:19.851504    2079 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://192.168.49.2:8443/api/v1/namespaces/default/events\": dial tcp 192.168.49.2:8443: connect: connection refused" event="&Event{ObjectMeta:{minikube.1858ce399cd6d19b  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Node,Namespace:,Name:minikube,UID:minikube,APIVersion:,ResourceVersion:,FieldPath:,},Reason:NodeHasSufficientMemory,Message:Node minikube status is now: NodeHasSufficientMemory,Source:EventSource{Component:kubelet,Host:minikube,},FirstTimestamp:2025-08-05 07:26:41.700589979 +0000 UTC m=+0.291769774,LastTimestamp:2025-08-05 07:26:41.700589979 +0000 UTC m=+0.291769774,Count:1,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:minikube,}"
Aug 05 07:30:21 minikube kubelet[2079]: E0805 07:30:21.773224    2079 eviction_manager.go:292] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"minikube\" not found"
Aug 05 07:30:24 minikube kubelet[2079]: E0805 07:30:24.801835    2079 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://192.168.49.2:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused" interval="7s"
Aug 05 07:30:24 minikube kubelet[2079]: I0805 07:30:24.812814    2079 kubelet_node_status.go:75] "Attempting to register node" node="minikube"
Aug 05 07:30:24 minikube kubelet[2079]: E0805 07:30:24.814091    2079 kubelet_node_status.go:107] "Unable to register node with API server" err="Post \"https://192.168.49.2:8443/api/v1/nodes\": dial tcp 192.168.49.2:8443: connect: connection refused" node="minikube"
Aug 05 07:30:28 minikube kubelet[2079]: E0805 07:30:28.279683    2079 reflector.go:200] "Failed to watch" err="failed to list *v1.RuntimeClass: Get \"https://192.168.49.2:8443/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.RuntimeClass"
Aug 05 07:30:29 minikube kubelet[2079]: E0805 07:30:29.712538    2079 kubelet.go:3305] "No need to create a mirror pod, since failed to get node info from the cluster" err="node \"minikube\" not found" node="minikube"
Aug 05 07:30:29 minikube kubelet[2079]: I0805 07:30:29.712619    2079 scope.go:117] "RemoveContainer" containerID="453838ea4ac61fd723957afa68425ff89e2ea7c2c805713098dccb4880260dbf"
Aug 05 07:30:29 minikube kubelet[2079]: E0805 07:30:29.852530    2079 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://192.168.49.2:8443/api/v1/namespaces/default/events\": dial tcp 192.168.49.2:8443: connect: connection refused" event="&Event{ObjectMeta:{minikube.1858ce399cd6d19b  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Node,Namespace:,Name:minikube,UID:minikube,APIVersion:,ResourceVersion:,FieldPath:,},Reason:NodeHasSufficientMemory,Message:Node minikube status is now: NodeHasSufficientMemory,Source:EventSource{Component:kubelet,Host:minikube,},FirstTimestamp:2025-08-05 07:26:41.700589979 +0000 UTC m=+0.291769774,LastTimestamp:2025-08-05 07:26:41.700589979 +0000 UTC m=+0.291769774,Count:1,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:minikube,}"
Aug 05 07:30:31 minikube kubelet[2079]: E0805 07:30:31.774452    2079 eviction_manager.go:292] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"minikube\" not found"
Aug 05 07:30:31 minikube kubelet[2079]: E0805 07:30:31.803215    2079 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://192.168.49.2:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused" interval="7s"
Aug 05 07:30:31 minikube kubelet[2079]: I0805 07:30:31.815438    2079 kubelet_node_status.go:75] "Attempting to register node" node="minikube"
Aug 05 07:30:31 minikube kubelet[2079]: E0805 07:30:31.815781    2079 kubelet_node_status.go:107] "Unable to register node with API server" err="Post \"https://192.168.49.2:8443/api/v1/nodes\": dial tcp 192.168.49.2:8443: connect: connection refused" node="minikube"
Aug 05 07:30:32 minikube kubelet[2079]: E0805 07:30:32.715079    2079 kubelet.go:3305] "No need to create a mirror pod, since failed to get node info from the cluster" err="node \"minikube\" not found" node="minikube"
Aug 05 07:30:32 minikube kubelet[2079]: I0805 07:30:32.715402    2079 scope.go:117] "RemoveContainer" containerID="8a22eb894ae102d2d8072f99c293fec4e075a8ceaf26c275818d80c05136e050"
Aug 05 07:30:32 minikube kubelet[2079]: E0805 07:30:32.715986    2079 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(0378f173c980f85a71d36305bacb0ad1)\"" pod="kube-system/kube-controller-manager-minikube" podUID="0378f173c980f85a71d36305bacb0ad1"
Aug 05 07:30:35 minikube kubelet[2079]: E0805 07:30:35.233478    2079 certificate_manager.go:596] "Failed while requesting a signed certificate from the control plane" err="cannot create certificate signing request: Post \"https://192.168.49.2:8443/apis/certificates.k8s.io/v1/certificatesigningrequests\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="kubernetes.io/kube-apiserver-client-kubelet.UnhandledError"
Aug 05 07:30:36 minikube kubelet[2079]: E0805 07:30:36.792647    2079 reflector.go:200] "Failed to watch" err="failed to list *v1.Node: Get \"https://192.168.49.2:8443/api/v1/nodes?fieldSelector=metadata.name%3Dminikube&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Node"
Aug 05 07:30:38 minikube kubelet[2079]: E0805 07:30:38.804189    2079 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://192.168.49.2:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused" interval="7s"
Aug 05 07:30:38 minikube kubelet[2079]: I0805 07:30:38.817275    2079 kubelet_node_status.go:75] "Attempting to register node" node="minikube"
Aug 05 07:30:38 minikube kubelet[2079]: E0805 07:30:38.817641    2079 kubelet_node_status.go:107] "Unable to register node with API server" err="Post \"https://192.168.49.2:8443/api/v1/nodes\": dial tcp 192.168.49.2:8443: connect: connection refused" node="minikube"
Aug 05 07:30:39 minikube kubelet[2079]: E0805 07:30:39.854181    2079 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://192.168.49.2:8443/api/v1/namespaces/default/events\": dial tcp 192.168.49.2:8443: connect: connection refused" event="&Event{ObjectMeta:{minikube.1858ce399cd6d19b  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Node,Namespace:,Name:minikube,UID:minikube,APIVersion:,ResourceVersion:,FieldPath:,},Reason:NodeHasSufficientMemory,Message:Node minikube status is now: NodeHasSufficientMemory,Source:EventSource{Component:kubelet,Host:minikube,},FirstTimestamp:2025-08-05 07:26:41.700589979 +0000 UTC m=+0.291769774,LastTimestamp:2025-08-05 07:26:41.700589979 +0000 UTC m=+0.291769774,Count:1,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:minikube,}"
Aug 05 07:30:41 minikube kubelet[2079]: I0805 07:30:41.736585    2079 scope.go:117] "RemoveContainer" containerID="453838ea4ac61fd723957afa68425ff89e2ea7c2c805713098dccb4880260dbf"
Aug 05 07:30:41 minikube kubelet[2079]: E0805 07:30:41.775493    2079 eviction_manager.go:292] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"minikube\" not found"
Aug 05 07:30:42 minikube systemd[1]: Stopping kubelet: The Kubernetes Node Agent...
Aug 05 07:30:42 minikube systemd[1]: kubelet.service: Deactivated successfully.
Aug 05 07:30:42 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Aug 05 07:30:42 minikube systemd[1]: kubelet.service: Consumed 3.956s CPU time.

